{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0egmh06tqZm7"
      },
      "source": [
        "Dowload the Required Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imzxxl61dxsx",
        "outputId": "522419d6-843b-45e1-81ea-756bd7af73f6"
      },
      "outputs": [],
      "source": [
        "pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjV0uAZKd4nJ",
        "outputId": "fd1a58de-7334-4d55-923c-63ac2eb5f248"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtfZa0W-eFzW",
        "outputId": "cbe9ac51-0b51-44f6-d079-35396ccbb2d9"
      },
      "outputs": [],
      "source": [
        "pip install openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt5qOrhAqefO"
      },
      "source": [
        "Open the Hyperlink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "khKImQHsgEHP"
      },
      "outputs": [],
      "source": [
        "import openpyxl\n",
        "\n",
        "workbook = openpyxl.load_workbook('/content/drive/MyDrive/20211030 Test Assignment/Input.xlsx')\n",
        "sheet = workbook.active\n",
        "\n",
        "hyperlinks = []\n",
        "\n",
        "for row in sheet.iter_rows():\n",
        "    for cell in row:\n",
        "        if cell.hyperlink:\n",
        "            hyperlinks.append(cell.hyperlink.target)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3WqzIguqjEh"
      },
      "source": [
        "# Extracting Titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D3Tvw7aKgN06"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "article_titles = []\n",
        "\n",
        "for link in hyperlinks:\n",
        "    response = requests.get(link)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    title = soup.find('h1').text\n",
        "    article_titles.append(title)\n",
        "\n",
        "# URL_ID save it in a text file\n",
        "\n",
        "with open('URL_ID.txt', 'w') as file:\n",
        "    for title in article_titles:\n",
        "        file.write(title + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcYGicEpqUOH"
      },
      "source": [
        "# Writing Output in the Excel File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oT0WeGdHhQ1m"
      },
      "outputs": [],
      "source": [
        "headTexts = []\n",
        "with open('URL_ID.txt', 'r') as file:\n",
        "    headTexts = file.readlines()\n",
        "    file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0dayhGLsWEz"
      },
      "source": [
        "# Using NLP techniques to perform textual analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAb1ePmcsLUx",
        "outputId": "1cc8a904-da61-4686-e0ad-5fca3ee9bda6"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB70nOlNxdjY"
      },
      "source": [
        "Removing Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LMqc9Pzrs1yT"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "title_list = []\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    headTexts = text\n",
        "    words = []\n",
        "    for sentence in headTexts:\n",
        "        tokens = nltk.word_tokenize(sentence)\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum()]\n",
        "        tokens = [word for word in tokens if word not in stopwords]\n",
        "        words.append(tokens)\n",
        "\n",
        "    return words\n",
        "\n",
        "title_list = remove_stopwords(headTexts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA6FUDxoAOig",
        "outputId": "cadf8f1e-74b0-4d74-d97d-06934c756b3a"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('opinion_lexicon')\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNTBiDD84uxx",
        "outputId": "7125ec69-fdf6-40fa-eb19-7018c2ad1031"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "joined_sentences = [' '.join(sentence) for sentence in title_list]\n",
        "polarity_scores = []\n",
        "\n",
        "for sentence in joined_sentences:\n",
        "    scores = sid.polarity_scores(sentence)\n",
        "    compound = scores['compound']\n",
        "    if compound >= 0.05:\n",
        "        sentiment = \"Positive\"\n",
        "    elif compound <= -0.05:\n",
        "        sentiment = \"Negative\"\n",
        "        # print(f\"Sentence: {sentence}\\nSentiment: {sentiment}, Polarity Score: {scores}, Sentence Length: {len(sentence)}\\n\")\n",
        "    polarity_scores.append(scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yfQy9N-gTA1q"
      },
      "outputs": [],
      "source": [
        "# Extract the 'polarity' value\n",
        "polarity_values = [score['compound'] for score in polarity_scores[:-1]]\n",
        "pos_values = [score['pos'] for score in polarity_scores[:-1]]\n",
        "neg_values = [score['neg'] for score in polarity_scores[:-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vT3DVjEBYz3h"
      },
      "outputs": [],
      "source": [
        "from openpyxl import load_workbook\n",
        "\n",
        "workbook = load_workbook('/content/drive/MyDrive/20211030 Test Assignment/Output Data Structure.xlsx')\n",
        "sheet = workbook.active\n",
        "\n",
        "header = [cell.value for cell in sheet[1]]\n",
        "polarity_col_index = header.index('POSITIVE SCORE') + 1\n",
        "\n",
        "for i, score in enumerate(pos_values, start=2):\n",
        "    sheet.cell(row=i, column=polarity_col_index, value=score)\n",
        "\n",
        "# Save the workbook\n",
        "workbook.save('Output Data Structure.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TgMvn1mEY4Gz"
      },
      "outputs": [],
      "source": [
        "from openpyxl import load_workbook\n",
        "\n",
        "workbook = load_workbook('Output Data Structure.xlsx')\n",
        "sheet = workbook.active\n",
        "\n",
        "header = [cell.value for cell in sheet[1]]\n",
        "polarity_col_index = header.index('NEGATIVE SCORE') + 1\n",
        "\n",
        "for i, score in enumerate(neg_values, start=2):\n",
        "    sheet.cell(row=i, column=polarity_col_index, value=score)\n",
        "\n",
        "workbook.save('Output Data Structure.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Kxl4sRlbfqDp"
      },
      "outputs": [],
      "source": [
        "from openpyxl import load_workbook\n",
        "\n",
        "workbook = load_workbook('Output Data Structure.xlsx')\n",
        "sheet = workbook.active\n",
        "\n",
        "header = [cell.value for cell in sheet[1]]\n",
        "polarity_col_index = header.index('POLARITY SCORE') + 1\n",
        "\n",
        "for i, score in enumerate(polarity_values, start=2):\n",
        "    sheet.cell(row=i, column=polarity_col_index, value=score)\n",
        "\n",
        "workbook.save('Output Data Structure.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "t99lNbHpkONM"
      },
      "outputs": [],
      "source": [
        "insertion_values = ['POSITIVE SCORE','NEGATIVE SCORE','POLARITY SCORE','SUBJECTIVITY SCORE','AVG SENTENCE LENGTH','PERCENTAGE OF COMPLEX WORDS','FOG INDEX','AVG NUMBER OF WORDS PER SENTENCE','COMPLEX WORD COUNT','WORD COUNT','SYLLABLE PER WORD','PERSONAL PRONOUNS','AVG WORD LENGTH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yILVtE_9ivns"
      },
      "outputs": [],
      "source": [
        "from openpyxl import load_workbook\n",
        "\n",
        "avg_senteces_length = []\n",
        "for word in title_list:\n",
        "    avg_senteces_length.append(len(word)/len(title_list))\n",
        "\n",
        "workbook = load_workbook('Output Data Structure.xlsx')\n",
        "sheet = workbook.active\n",
        "\n",
        "header = [cell.value for cell in sheet[1]]\n",
        "polarity_col_index = header.index('AVG SENTENCE LENGTH') + 1\n",
        "\n",
        "for i, score in enumerate(avg_senteces_length, start=2):\n",
        "    sheet.cell(row=i, column=polarity_col_index, value=score)\n",
        "\n",
        "workbook.save('Output Data Structure.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TuCOnHdVdbRp"
      },
      "outputs": [],
      "source": [
        "# Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
        "avg_senteces_length = []\n",
        "complex_words = []\n",
        "\n",
        "for word in title_list:\n",
        "    avg_senteces_length.append(len(word)/len(title_list))\n",
        "for title in title_list:\n",
        "  for word in title:\n",
        "    if word.islower():\n",
        "      complex_words.append(word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gTrBWz2jRDX",
        "outputId": "bd262605-f485-485d-a7eb-0f90c308fd5f"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMU-C47-wRJD"
      },
      "outputs": [],
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "d = cmudict.dict()\n",
        "\n",
        "def count_syllables(word):\n",
        "    if word.lower() in d:\n",
        "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def is_complex_word(word, syllable_threshold=3, length_threshold=7):\n",
        "    syllables = count_syllables(word)\n",
        "    return syllables >= syllable_threshold or len(word) >= length_threshold\n",
        "\n",
        "def find_complex_words(sentence, syllable_threshold=3, length_threshold=7):\n",
        "    words = nltk.word_tokenize(sentence)\n",
        "    complex_words = [word for word in words if is_complex_word(word, syllable_threshold, length_threshold)]\n",
        "    return complex_words\n",
        "\n",
        "complex_words = []\n",
        "for i in range(len(joined_sentences)):\n",
        "  sentence = joined_sentences[i]\n",
        "  complex_words.append(find_complex_words(sentence))\n",
        "\n",
        "complex_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL9F-XjE6I3Z",
        "outputId": "48750594-4fd6-4124-8376-de95609e9850"
      },
      "outputs": [],
      "source": [
        "len(pos_values), len(neg_values), len(joined_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "6lAkLfo4wV3v"
      },
      "outputs": [],
      "source": [
        "list1 = []\n",
        "for i in range(len(joined_sentences)-1):\n",
        "  list1.append(float(((pos_values[i] + neg_values[i])/len(joined_sentences[i]) + 0.000001)))\n",
        "\n",
        "subj_score = []\n",
        "for i in range(len(list1)):\n",
        "  subj_score.append(f\"{list1[i]:.10f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "rPBjEng38CDx"
      },
      "outputs": [],
      "source": [
        "workbook = load_workbook('Output Data Structure.xlsx')\n",
        "sheet = workbook.active\n",
        "\n",
        "header = [cell.value for cell in sheet[1]]\n",
        "polarity_col_index = header.index('SUBJECTIVITY SCORE') + 1\n",
        "\n",
        "for i, score in enumerate(subj_score, start=2):\n",
        "    sheet.cell(row=i, column=polarity_col_index, value=score)\n",
        "\n",
        "workbook.save('Output Data Structure.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "gAXNx6Zu8RFH"
      },
      "outputs": [],
      "source": [
        "sheet = workbook['Sheet1']\n",
        "sheet.delete_cols(8, 1)\n",
        "sheet.delete_cols(11, 1)\n",
        "sheet.delete_cols(12, 1)\n",
        "\n",
        "workbook.save('Output Data Structure.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmq-teH8CDo-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
